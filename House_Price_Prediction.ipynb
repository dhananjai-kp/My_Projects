{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NA</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL          65     8450   Pave    NA      Reg   \n",
       "1   2          20       RL          80     9600   Pave    NA      Reg   \n",
       "2   3          60       RL          68    11250   Pave    NA      IR1   \n",
       "3   4          70       RL          60     9550   Pave    NA      IR1   \n",
       "4   5          60       RL          84    14260   Pave    NA      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0     NA    NA          NA       0      2   \n",
       "1         Lvl    AllPub  ...        0     NA    NA          NA       0      5   \n",
       "2         Lvl    AllPub  ...        0     NA    NA          NA       0      9   \n",
       "3         Lvl    AllPub  ...        0     NA    NA          NA       0      2   \n",
       "4         Lvl    AllPub  ...        0     NA    NA          NA       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv',na_filter=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['SalePrice'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Id             1460 non-null   int64 \n",
      " 1   MSSubClass     1460 non-null   int64 \n",
      " 2   MSZoning       1460 non-null   object\n",
      " 3   LotFrontage    1460 non-null   object\n",
      " 4   LotArea        1460 non-null   int64 \n",
      " 5   Street         1460 non-null   object\n",
      " 6   Alley          1460 non-null   object\n",
      " 7   LotShape       1460 non-null   object\n",
      " 8   LandContour    1460 non-null   object\n",
      " 9   Utilities      1460 non-null   object\n",
      " 10  LotConfig      1460 non-null   object\n",
      " 11  LandSlope      1460 non-null   object\n",
      " 12  Neighborhood   1460 non-null   object\n",
      " 13  Condition1     1460 non-null   object\n",
      " 14  Condition2     1460 non-null   object\n",
      " 15  BldgType       1460 non-null   object\n",
      " 16  HouseStyle     1460 non-null   object\n",
      " 17  OverallQual    1460 non-null   int64 \n",
      " 18  OverallCond    1460 non-null   int64 \n",
      " 19  YearBuilt      1460 non-null   int64 \n",
      " 20  YearRemodAdd   1460 non-null   int64 \n",
      " 21  RoofStyle      1460 non-null   object\n",
      " 22  RoofMatl       1460 non-null   object\n",
      " 23  Exterior1st    1460 non-null   object\n",
      " 24  Exterior2nd    1460 non-null   object\n",
      " 25  MasVnrType     1460 non-null   object\n",
      " 26  MasVnrArea     1460 non-null   object\n",
      " 27  ExterQual      1460 non-null   object\n",
      " 28  ExterCond      1460 non-null   object\n",
      " 29  Foundation     1460 non-null   object\n",
      " 30  BsmtQual       1460 non-null   object\n",
      " 31  BsmtCond       1460 non-null   object\n",
      " 32  BsmtExposure   1460 non-null   object\n",
      " 33  BsmtFinType1   1460 non-null   object\n",
      " 34  BsmtFinSF1     1460 non-null   int64 \n",
      " 35  BsmtFinType2   1460 non-null   object\n",
      " 36  BsmtFinSF2     1460 non-null   int64 \n",
      " 37  BsmtUnfSF      1460 non-null   int64 \n",
      " 38  TotalBsmtSF    1460 non-null   int64 \n",
      " 39  Heating        1460 non-null   object\n",
      " 40  HeatingQC      1460 non-null   object\n",
      " 41  CentralAir     1460 non-null   object\n",
      " 42  Electrical     1460 non-null   object\n",
      " 43  1stFlrSF       1460 non-null   int64 \n",
      " 44  2ndFlrSF       1460 non-null   int64 \n",
      " 45  LowQualFinSF   1460 non-null   int64 \n",
      " 46  GrLivArea      1460 non-null   int64 \n",
      " 47  BsmtFullBath   1460 non-null   int64 \n",
      " 48  BsmtHalfBath   1460 non-null   int64 \n",
      " 49  FullBath       1460 non-null   int64 \n",
      " 50  HalfBath       1460 non-null   int64 \n",
      " 51  BedroomAbvGr   1460 non-null   int64 \n",
      " 52  KitchenAbvGr   1460 non-null   int64 \n",
      " 53  KitchenQual    1460 non-null   object\n",
      " 54  TotRmsAbvGrd   1460 non-null   int64 \n",
      " 55  Functional     1460 non-null   object\n",
      " 56  Fireplaces     1460 non-null   int64 \n",
      " 57  FireplaceQu    1460 non-null   object\n",
      " 58  GarageType     1460 non-null   object\n",
      " 59  GarageYrBlt    1460 non-null   object\n",
      " 60  GarageFinish   1460 non-null   object\n",
      " 61  GarageCars     1460 non-null   int64 \n",
      " 62  GarageArea     1460 non-null   int64 \n",
      " 63  GarageQual     1460 non-null   object\n",
      " 64  GarageCond     1460 non-null   object\n",
      " 65  PavedDrive     1460 non-null   object\n",
      " 66  WoodDeckSF     1460 non-null   int64 \n",
      " 67  OpenPorchSF    1460 non-null   int64 \n",
      " 68  EnclosedPorch  1460 non-null   int64 \n",
      " 69  3SsnPorch      1460 non-null   int64 \n",
      " 70  ScreenPorch    1460 non-null   int64 \n",
      " 71  PoolArea       1460 non-null   int64 \n",
      " 72  PoolQC         1460 non-null   object\n",
      " 73  Fence          1460 non-null   object\n",
      " 74  MiscFeature    1460 non-null   object\n",
      " 75  MiscVal        1460 non-null   int64 \n",
      " 76  MoSold         1460 non-null   int64 \n",
      " 77  YrSold         1460 non-null   int64 \n",
      " 78  SaleType       1460 non-null   object\n",
      " 79  SaleCondition  1460 non-null   object\n",
      " 80  SalePrice      1460 non-null   int64 \n",
      "dtypes: int64(35), object(46)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NA      1369\n",
       "Grvl      50\n",
       "Pave      41\n",
       "Name: Alley, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Alley'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for col in df_train.columns:\n",
    "#     print('-' * 10 + col + '-' * 10)\n",
    "#     display(df_train[col].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
       "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
       "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
       "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
       "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
       "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
       "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
       "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
       "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
       "       'SaleCondition', 'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id  =  [   1    2    3 ... 1458 1459 1460]\n",
      "MSSubClass  =  [ 60  20  70  50 190  45  90 120  30  85  80 160  75 180  40]\n",
      "MSZoning  =  ['RL' 'RM' 'C (all)' 'FV' 'RH']\n",
      "LotFrontage  =  ['65' '80' '68' '60' '84' '85' '75' 'NA' '51' '50' '70' '91' '72' '66'\n",
      " '101' '57' '44' '110' '98' '47' '108' '112' '74' '115' '61' '48' '33'\n",
      " '52' '100' '24' '89' '63' '76' '81' '95' '69' '21' '32' '78' '121' '122'\n",
      " '40' '105' '73' '77' '64' '94' '34' '90' '55' '88' '82' '71' '120' '107'\n",
      " '92' '134' '62' '86' '141' '97' '54' '41' '79' '174' '99' '67' '83' '43'\n",
      " '103' '93' '30' '129' '140' '35' '37' '118' '87' '116' '150' '111' '49'\n",
      " '96' '59' '36' '56' '102' '58' '38' '109' '130' '53' '137' '45' '106'\n",
      " '104' '42' '39' '144' '114' '128' '149' '313' '168' '182' '138' '160'\n",
      " '152' '124' '153' '46']\n",
      "LotArea  =  [ 8450  9600 11250 ... 17217 13175  9717]\n",
      "Street  =  ['Pave' 'Grvl']\n",
      "Alley  =  ['NA' 'Grvl' 'Pave']\n",
      "LotShape  =  ['Reg' 'IR1' 'IR2' 'IR3']\n",
      "LandContour  =  ['Lvl' 'Bnk' 'Low' 'HLS']\n",
      "Utilities  =  ['AllPub' 'NoSeWa']\n",
      "LotConfig  =  ['Inside' 'FR2' 'Corner' 'CulDSac' 'FR3']\n",
      "LandSlope  =  ['Gtl' 'Mod' 'Sev']\n",
      "Neighborhood  =  ['CollgCr' 'Veenker' 'Crawfor' 'NoRidge' 'Mitchel' 'Somerst' 'NWAmes'\n",
      " 'OldTown' 'BrkSide' 'Sawyer' 'NridgHt' 'NAmes' 'SawyerW' 'IDOTRR'\n",
      " 'MeadowV' 'Edwards' 'Timber' 'Gilbert' 'StoneBr' 'ClearCr' 'NPkVill'\n",
      " 'Blmngtn' 'BrDale' 'SWISU' 'Blueste']\n",
      "Condition1  =  ['Norm' 'Feedr' 'PosN' 'Artery' 'RRAe' 'RRNn' 'RRAn' 'PosA' 'RRNe']\n",
      "Condition2  =  ['Norm' 'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe']\n",
      "BldgType  =  ['1Fam' '2fmCon' 'Duplex' 'TwnhsE' 'Twnhs']\n",
      "HouseStyle  =  ['2Story' '1Story' '1.5Fin' '1.5Unf' 'SFoyer' 'SLvl' '2.5Unf' '2.5Fin']\n",
      "OverallQual  =  [ 7  6  8  5  9  4 10  3  1  2]\n",
      "OverallCond  =  [5 8 6 7 4 2 3 9 1]\n",
      "YearBuilt  =  [2003 1976 2001 1915 2000 1993 2004 1973 1931 1939 1965 2005 1962 2006\n",
      " 1960 1929 1970 1967 1958 1930 2002 1968 2007 1951 1957 1927 1920 1966\n",
      " 1959 1994 1954 1953 1955 1983 1975 1997 1934 1963 1981 1964 1999 1972\n",
      " 1921 1945 1982 1998 1956 1948 1910 1995 1991 2009 1950 1961 1977 1985\n",
      " 1979 1885 1919 1990 1969 1935 1988 1971 1952 1936 1923 1924 1984 1926\n",
      " 1940 1941 1987 1986 2008 1908 1892 1916 1932 1918 1912 1947 1925 1900\n",
      " 1980 1989 1992 1949 1880 1928 1978 1922 1996 2010 1946 1913 1937 1942\n",
      " 1938 1974 1893 1914 1906 1890 1898 1904 1882 1875 1911 1917 1872 1905]\n",
      "YearRemodAdd  =  [2003 1976 2002 1970 2000 1995 2005 1973 1950 1965 2006 1962 2007 1960\n",
      " 2001 1967 2004 2008 1997 1959 1990 1955 1983 1980 1966 1963 1987 1964\n",
      " 1972 1996 1998 1989 1953 1956 1968 1981 1992 2009 1982 1961 1993 1999\n",
      " 1985 1979 1977 1969 1958 1991 1971 1952 1975 2010 1984 1986 1994 1988\n",
      " 1954 1957 1951 1978 1974]\n",
      "RoofStyle  =  ['Gable' 'Hip' 'Gambrel' 'Mansard' 'Flat' 'Shed']\n",
      "RoofMatl  =  ['CompShg' 'WdShngl' 'Metal' 'WdShake' 'Membran' 'Tar&Grv' 'Roll'\n",
      " 'ClyTile']\n",
      "Exterior1st  =  ['VinylSd' 'MetalSd' 'Wd Sdng' 'HdBoard' 'BrkFace' 'WdShing' 'CemntBd'\n",
      " 'Plywood' 'AsbShng' 'Stucco' 'BrkComm' 'AsphShn' 'Stone' 'ImStucc'\n",
      " 'CBlock']\n",
      "Exterior2nd  =  ['VinylSd' 'MetalSd' 'Wd Shng' 'HdBoard' 'Plywood' 'Wd Sdng' 'CmentBd'\n",
      " 'BrkFace' 'Stucco' 'AsbShng' 'Brk Cmn' 'ImStucc' 'AsphShn' 'Stone'\n",
      " 'Other' 'CBlock']\n",
      "MasVnrType  =  ['BrkFace' 'None' 'Stone' 'BrkCmn' 'NA']\n",
      "MasVnrArea  =  ['196' '0' '162' '350' '186' '240' '286' '306' '212' '180' '380' '281'\n",
      " '640' '200' '246' '132' '650' '101' '412' '272' '456' '1031' '178' '573'\n",
      " '344' '287' '167' '1115' '40' '104' '576' '443' '468' '66' '22' '284'\n",
      " '76' '203' '68' '183' '48' '28' '336' '600' '768' '480' '220' '184'\n",
      " '1129' '116' '135' '266' '85' '309' '136' '288' '70' '320' '50' '120'\n",
      " '436' '252' '84' '664' '226' '300' '653' '112' '491' '268' '748' '98'\n",
      " '275' '138' '205' '262' '128' '260' '153' '64' '312' '16' '922' '142'\n",
      " '290' '127' '506' '297' 'NA' '604' '254' '36' '102' '472' '481' '108'\n",
      " '302' '172' '399' '270' '46' '210' '174' '348' '315' '299' '340' '166'\n",
      " '72' '31' '34' '238' '1600' '365' '56' '150' '278' '256' '225' '370'\n",
      " '388' '175' '296' '146' '113' '176' '616' '30' '106' '870' '362' '530'\n",
      " '500' '510' '247' '305' '255' '125' '100' '432' '126' '473' '74' '145'\n",
      " '232' '376' '42' '161' '110' '18' '224' '248' '80' '304' '215' '772'\n",
      " '435' '378' '562' '168' '89' '285' '360' '94' '333' '921' '762' '594'\n",
      " '219' '188' '479' '584' '182' '250' '292' '245' '207' '82' '97' '335'\n",
      " '208' '420' '170' '459' '280' '99' '192' '204' '233' '156' '452' '513'\n",
      " '261' '164' '259' '209' '263' '216' '351' '660' '381' '54' '528' '258'\n",
      " '464' '57' '147' '1170' '293' '630' '466' '109' '41' '160' '289' '651'\n",
      " '169' '95' '442' '202' '338' '894' '328' '673' '603' '1' '375' '90' '38'\n",
      " '157' '11' '140' '130' '148' '860' '424' '1047' '243' '816' '387' '223'\n",
      " '158' '137' '115' '189' '274' '117' '60' '122' '92' '415' '760' '27' '75'\n",
      " '361' '105' '342' '298' '541' '236' '144' '423' '44' '151' '975' '450'\n",
      " '230' '571' '24' '53' '206' '14' '324' '295' '396' '67' '154' '425' '45'\n",
      " '1378' '337' '149' '143' '51' '171' '234' '63' '766' '32' '81' '163'\n",
      " '554' '218' '632' '114' '567' '359' '451' '621' '788' '86' '796' '391'\n",
      " '228' '88' '165' '428' '410' '564' '368' '318' '579' '65' '705' '408'\n",
      " '244' '123' '366' '731' '448' '294' '310' '237' '426' '96' '438' '194'\n",
      " '119']\n",
      "ExterQual  =  ['Gd' 'TA' 'Ex' 'Fa']\n",
      "ExterCond  =  ['TA' 'Gd' 'Fa' 'Po' 'Ex']\n",
      "Foundation  =  ['PConc' 'CBlock' 'BrkTil' 'Wood' 'Slab' 'Stone']\n",
      "BsmtQual  =  ['Gd' 'TA' 'Ex' 'NA' 'Fa']\n",
      "BsmtCond  =  ['TA' 'Gd' 'NA' 'Fa' 'Po']\n",
      "BsmtExposure  =  ['No' 'Gd' 'Mn' 'Av' 'NA']\n",
      "BsmtFinType1  =  ['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' 'NA' 'LwQ']\n",
      "BsmtFinSF1  =  [ 706  978  486  216  655  732 1369  859    0  851  906  998  737  733\n",
      "  578  646  504  840  188  234 1218 1277 1018 1153 1213  731  643  967\n",
      "  747  280  179  456 1351   24  763  182  104 1810  384  490  649  632\n",
      "  941  739  912 1013  603 1880  565  320  462  228  336  448 1201   33\n",
      "  588  600  713 1046  648  310 1162  520  108  569 1200  224  705  444\n",
      "  250  984   35  774  419  170 1470  938  570  300  120  116  512  567\n",
      "  445  695  405 1005  668  821  432 1300  507  679 1332  209  680  716\n",
      " 1400  416  429  222   57  660 1016  370  351  379 1288  360  639  495\n",
      "  288 1398  477  831 1904  436  352  611 1086  297  626  560  390  566\n",
      " 1126 1036 1088  641  617  662  312 1065  787  468   36  822  378  946\n",
      "  341   16  550  524   56  321  842  689  625  358  402   94 1078  329\n",
      "  929  697 1573  270  922  503 1334  361  672  506  714  403  751  226\n",
      "  620  546  392  421  905  904  430  614  450  210  292  795 1285  819\n",
      "  420  841  281  894 1464  700  262 1274  518 1236  425  692  987  970\n",
      "   28  256 1619   40  846 1124  720  828 1249  810  213  585  129  498\n",
      " 1270  573 1410 1082  236  388  334  874  956  773  399  162  712  609\n",
      "  371  540   72  623  428  350  298 1445  218  985  631 1280  241  690\n",
      "  266  777  812  786 1116  789 1056   50 1128  775 1309 1246  986  616\n",
      " 1518  664  387  471  385  365 1767  133  642  247  331  742 1606  916\n",
      "  185  544  553  326  778  386  426  368  459 1350 1196  630  994  168\n",
      " 1261 1567  299  897  607  836  515  374 1231  111  356  400  698 1247\n",
      "  257  380   27  141  991  650  521 1436 2260  719  377 1330  348 1219\n",
      "  783  969  673 1358 1260  144  584  554 1002  619  180  559  308  866\n",
      "  895  637  604 1302 1071  290  728    2 1441  943  231  414  349  442\n",
      "  328  594  816 1460 1324 1338  685 1422 1283   81  454  903  605  990\n",
      "  206  150  457   48  871   41  674  624  480 1154  738  493 1121  282\n",
      "  500  131 1696  806 1361  920 1721  187 1138  988  193  551  767 1186\n",
      "  892  311  827  543 1003 1059  239  945   20 1455  965  980  863  533\n",
      " 1084 1173  523 1148  191 1234  375  808  724  152 1180  252  832  575\n",
      "  919  439  381  438  549  612 1163  437  394 1416  422  762  975 1097\n",
      "  251  686  656  568  539  862  197  516  663  608 1636  784  249 1040\n",
      "  483  196  572  338  330  156 1390  513  460  659  364  564  306  505\n",
      "  932  750   64  633 1170  899  902 1238  528 1024 1064  285 2188  465\n",
      "  322  860  599  354   63  223  301  443  489  284  294  814  165  552\n",
      "  833  464  936  772 1440  748  982  398  562  484  417  699  696  896\n",
      "  556 1106  651  867  854 1646 1074  536 1172  915  595 1237  273  684\n",
      "  324 1165  138 1513  317 1012 1022  509  900 1085 1104  240  383  644\n",
      "  397  740  837  220  586  535  410   75  824  592 1039  510  423  661\n",
      "  248  704  412 1032  219  708  415 1004  353  702  369  622  212  645\n",
      "  852 1150 1258  275  176  296  538 1157  492 1198 1387  522  658 1216\n",
      " 1480 2096 1159  440 1456  883  547  788  485  340 1220  427  344  756\n",
      " 1540  666  803 1000  885 1386  319  534  125 1314  602  192  593  804\n",
      " 1053  532 1158 1014  194  167  776 5644  694 1572  746 1406  925  482\n",
      "  189  765   80 1443  259  735  734 1447  548  315 1282  408  309  203\n",
      "  865  204  790 1320  769 1070  264  759 1373  976  781   25 1110  404\n",
      "  580  678  958 1336 1079   49  830]\n",
      "BsmtFinType2  =  ['Unf' 'BLQ' 'NA' 'ALQ' 'Rec' 'LwQ' 'GLQ']\n",
      "BsmtFinSF2  =  [   0   32  668  486   93  491  506  712  362   41  169  869  150  670\n",
      "   28 1080  181  768  215  374  208  441  184  279  306  180  580  690\n",
      "  692  228  125 1063  620  175  820 1474  264  479  147  232  380  544\n",
      "  294  258  121  391  531  344  539  713  210  311 1120  165  532   96\n",
      "  495  174 1127  139  202  645  123  551  219  606  612  480  182  132\n",
      "  336  468  287   35  499  723  119   40  117  239   80  472   64 1057\n",
      "  127  630  128  377  764  345 1085  435  823  500  290  324  634  411\n",
      "  841 1061  466  396  354  149  193  273  465  400  682  557  230  106\n",
      "  791  240  547  469  177  108  600  492  211  168 1031  438  375  144\n",
      "   81  906  608  276  661   68  173  972  105  420  546  334  352  872\n",
      "  110  627  163 1029]\n",
      "BsmtUnfSF  =  [ 150  284  434  540  490   64  317  216  952  140  134  177  175 1494\n",
      "  520  832  426    0  468  525 1158  637 1777  200  204 1566  180  486\n",
      "  207  649 1228 1234  380  408 1117 1097   84  326  445  383  167  465\n",
      " 1296   83 1632  736  192  612  816   32  935  321  860 1410  148  217\n",
      "  530 1346  576  318 1143 1035  440  747  701  343  280  404  840  724\n",
      "  295 1768  448   36 1530 1065  384 1288  684 1013  402  635  163  168\n",
      "  176  370  350  381  410  741 1226 1053  641  516  793 1139  550  905\n",
      "  104  310  252 1125  203  728  732  510  899 1362   30  958  556  413\n",
      "  479  297  658  262  891 1304  519 1907  336  107  432  403  811  396\n",
      "  970  506  884  400  896  253  409   93 1200  572  774  769 1335  340\n",
      "  882  779  112  470  294 1686  360  441  354  700  725  320  554  312\n",
      "  968  504 1107  577  660   99  871  474  289  600  755  625 1121  276\n",
      "  186 1424 1140  375   92  305 1176   78  274  311  710  686  457 1232\n",
      " 1498 1010  160 2336  630  638  162   70 1357 1194  773  483  235  125\n",
      " 1390  594 1694  488  357  626  916 1020 1367  798  452  392  975  361\n",
      "  270  602 1482  680  606   88  342  212 1095   96  628 1560  744 2121\n",
      "  768  386 1468 1145  244  698 1079  570  476  131  184  143 1092  324\n",
      " 1541 1470  536  319  599  622  179  292  286   80  712  291  153 1088\n",
      " 1249  166  906  604  100  818  844  596  210 1603  115  103  673  726\n",
      "  995  967  721 1656  972  460  208  191  438 1869  371  624  552  322\n",
      "  598  268  130  484  785  733  953  847  333 1580  411  982  808 1293\n",
      "  939  784  595  229  114  522  735  405  117  961 1286  672 1141  806\n",
      "  165 1064 1063  245 1276  892 1008  499 1316  463  242  444  281   35\n",
      "  356  988  580  651  619  544  387  901  926  135  648   75  788 1307\n",
      " 1078 1258  273 1436  557  930  780  813  878  122  248  588  524  288\n",
      "  389  424 1375 1626  406  298 2153  417  739  225  611  237  290  264\n",
      "  238  363  190 1969  697  414  316  466  420  254  960  397 1191  548\n",
      "   50  178 1368  169  748  689 1264  467  605 1257  551  678  707  880\n",
      "  378  223  578  969  379  765  149  912  620 1709  132  993  197 1374\n",
      "   90  195  706 1163  367 1122 1515   55 1497  450  846   23  390  861\n",
      "  285 1050  331 2042 1237  113  742  924  512  119  314  308  293  537\n",
      "  126  427  309  914  173 1774  823  485 1116  978  636  564  108 1184\n",
      "  796  366  300  542  645  664  756  247  776  849 1392   38 1406  111\n",
      "  545  121 2046  161  261  567 1195  874 1342  151  989 1073  927  219\n",
      "  224  526 1164  761  461  876  859  171  718  138  941  464  250   72\n",
      "  508 1584  415   82  948  893  864 1349   76  487  652 1240  801  279\n",
      " 1030  348  234 1198  740   89  586  323 1836  480  456 1935  338 1594\n",
      "  102  374 1413  491 1129  255 1496  650 1926  154  999 1734  124 1417\n",
      "   15  834 1649  936  778 1489  442 1434  352  458 1221 1099  416 1800\n",
      "  227  907  528  189 1273  563  372  702 1090  435  198 1372  174 1638\n",
      "  894  299  105  676 1120  431  218  110  795 1098 1043  481  666  142\n",
      "  447  783 1670  277  412  794  239  662 1072  717  546  430  422  188\n",
      "  266 1181 1753  964 1450 1905 1480  772 1032  220  187   29  495  640\n",
      "  193  196  720  918 1428   77 1266 1128  692  770  750 1442 1007  501\n",
      "  691 1550 1680 1330 1710  746  814  515  571  359  355  301  668  920\n",
      " 1055 1420 1752  304 1302  833  133  549  705  722  799  462  429  810\n",
      "  155  170  230 1459 1082  758 1290 1074  251  172  868  797  365  418\n",
      "  730  533  671 1012 1528 1005 1373  500  762  752  399 1042   40   26\n",
      "  932  278  459  568 1502  543  574  977  449  983  731  120  538  831\n",
      "  994  341  879  815 1212  866 1630  328  141  364 1380   81  303  940\n",
      "  764 1048  334 1689  690  792  585  473  246 1045 1405  201   14  841\n",
      " 1104  241  925 2002   74  661  708 1152  256  804  812 1085  344  425\n",
      " 1616  976  496  349  971 1393 1622 1352 1795 1017 1588  428  803  693\n",
      "  858 1284 1203 1652   39  539 1217  257  715  616  240  315 1351 1026\n",
      " 1571  156   61   95  482 1094   60  862  221  791  398  777  503  734\n",
      "  709 1252  656 1319 1422  560 1573  589  877  136]\n",
      "TotalBsmtSF  =  [ 856 1262  920  756 1145  796 1686 1107  952  991 1040 1175  912 1494\n",
      " 1253  832 1004    0 1114 1029 1158  637 1777 1060 1566  900 1704 1484\n",
      "  520  649 1228 1234 1398 1561 1117 1097 1297 1057 1088 1350  840  938\n",
      " 1150 1752 1434 1656  736  955  794  816 1842  384 1425  970  860 1410\n",
      "  780  530 1370  576 1143 1947 1453  747 1304 2223  845 1086  462  672\n",
      " 1768  440  896 1237 1563 1065 1288  684  612 1013  990 1235  876 1214\n",
      "  824  680 1588  960  458  950 1610  741 1226 1053  641  789  793 1844\n",
      "  994 1264 1809 1028  729 1092 1125 1673  728  732 1080 1199 1362 1078\n",
      "  660 1008  924  992 1063 1267 1461 1907  928  864 1734  910 1490 1728\n",
      "  715  884  969 1710  825 1602 1200  572  774 1392 1232 1572 1541  882\n",
      " 1149  644 1617 1582  720 1064 1606 1202 1151 1052 2216  968  504 1188\n",
      " 1593  853  725 1431  855 1726 1360  755 1713 1121 1196  617  848 1424\n",
      " 1140 1100 1157 1212  689 1070 1436  686  798 1248 1498 1010  713 2392\n",
      "  630 1203  483 1373 1194 1462  894 1414  996 1694  735  540  626  948\n",
      " 1845 1020 1367 1444 1573 1302 1314  975 1604  963 1482  506  926 1422\n",
      "  802  740 1095 1385 1152 1240 1560 2121 1160  807 1468 1575  625  858\n",
      "  698 1079  768  795 1416 1003  702 1165 1470 2000  700  319  861 1896\n",
      "  697  972 2136  716 1347 1372 1249 1136 1502 1162  710 1719 1383  844\n",
      "  596 1056 3206 1358  943 1499 1922 1536 1208 1215  967  721 1684  536\n",
      "  958 1478  764 1848 1869  616  624  940 1142 1062  888  883 1394 1099\n",
      " 1268  953  744  608  847  683  870 1580 1856  982 1026 1293  939  784\n",
      " 1256  658 1041 1682  804  788 1144  961 1260 1310 1141  806 1281 1034\n",
      " 1276 1340 1344  988  651 1518  907  901  765  799  648 3094 1440 1258\n",
      "  915 1517  930  813 1533  872 1242 1364  588  709  560 1375 1277 1626\n",
      " 1488  808  547 1976 2153 1705 1833 1792 1216  999 1113 1073  954  264\n",
      " 1269  190 3200  866 1501  777 1218 1368 1084 2006 1244 3138 1379 1257\n",
      " 1452  528 2035  611  707  880 1051 1581 1838 1650  723  654 1204 1069\n",
      " 1709  998  993 1374 1389 1163 1122 1496  846  372 1164 1050 2042 1868\n",
      " 1437  742  770 1722 1814 1430 1058  908  600  965 1032 1299 1120  936\n",
      "  783 1822 1522  980 1116  978 1156  636 1554 1386  811 1520 1952 1766\n",
      "  981 1094 2109  525  776 1486 1629 1138 2077 1406 1021 1408  738 1477\n",
      " 2046  923 1291 1195 1190  874  551 1419 2444 1210  927 1112 1391 1800\n",
      "  360 1473 1643 1324  270  859  718 1176 1311  971 1742  941 1698 1584\n",
      " 1595  868 1153  893 1349 1337 1720 1479 1030 1318 1252  983 1860  836\n",
      " 1935 1614  761 1413  956  712  650  773 1926  731 1417 1024  849 1442\n",
      " 1649 1568  778 1489 2078 1454 1516 1067 1559 1127 1390 1273  918 1763\n",
      " 1090 1054 1039 1148 1002 1638  105  676 1184 1109  892 2217 1505 1059\n",
      "  951 2330 1670 1623 1017 1105 1001  546  480 1134 1104 1272 1316 1126\n",
      " 1181 1753  964 1466  925 1905 1500  585 1632  819 1616 1161  828  945\n",
      "  979  561  696 1330  817 1098 1428  673 1241  944 1225 1266 1128  485\n",
      " 1930 1396  916  822  750 1700 1007 1187  691 1574 1680 1346  985 1657\n",
      "  602 1022 1082  810 1504 1220 1132 1565 1338 1654 1620 1055  800 1306\n",
      " 1475 2524 1992 1193  973  854  662 1103 1154  942 1048  727  690 1096\n",
      " 1459 1251 1247 1074 1271  290  655 1463 1836  803  833  408  533 1012\n",
      " 1552 1005 1530  974 1567 1006 1042 1298  704  932 1219 1296 1198  959\n",
      " 1261 1598 1683  818 1600 2396 1624  831 1224  663  879  815 1630 2158\n",
      "  931 1660  559 1300 1702 1075 1361 1106 1476 1689 2076  792 2110 1405\n",
      " 1192  746 1986  841 2002 1332  935 1019  661 1309 1328 1085 6110 1246\n",
      "  771  976 1652 1278 1902 1274 1393 1622 1352  420 1795  544 1510  911\n",
      "  693 1284 1732 2033  570 1980  814  873  757 1108 2633 1571  984 1205\n",
      "  714 1746 1525  482 1356  862  839 1286 1485 1594  622  791  708 1223\n",
      "  913  656 1319 1932  539 1221 1542]\n",
      "Heating  =  ['GasA' 'GasW' 'Grav' 'Wall' 'OthW' 'Floor']\n",
      "HeatingQC  =  ['Ex' 'Gd' 'TA' 'Fa' 'Po']\n",
      "CentralAir  =  ['Y' 'N']\n",
      "Electrical  =  ['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' 'NA']\n",
      "1stFlrSF  =  [ 856 1262  920  961 1145  796 1694 1107 1022 1077 1040 1182  912 1494\n",
      " 1253  854 1004 1296 1114 1339 1158 1108 1795 1060 1600  900 1704  520\n",
      "  649 1228 1234 1700 1561 1132 1097 1297 1057 1152 1324 1328  884  938\n",
      " 1150 1752 1518 1656  736  955  794  816 1842 1360 1425  983  860 1426\n",
      "  780  581 1370  902 1143 2207 1479  747 1304 2223  845  885 1086  840\n",
      "  526  952 1072 1768  682 1337 1563 1065  804 1301  684  612 1013  990\n",
      " 1235  964 1260  905  680 1588  960  835 1225 1610  977 1535 1226 1053\n",
      " 1047  789  997 1844 1216  774 1282 2259 1436  729 1092 1125 1699  728\n",
      "  988  772 1080 1199 1586  958  660 1327 1721 1682 1214 1959  928  864\n",
      " 1734  910 1501 1728  970  875  896  969 1710 1252 1200  572  991 1392\n",
      " 1232 1572 1541  882 1149  808 1867 1707 1064 1362 1651 2158 1164 2234\n",
      "  968  769  901 1340  936 1217 1224 1593 1549  725 1431  855 1726  929\n",
      " 1713 1121 1279  865  848  720 1442 1696 1100 1180 1212  932  689 1236\n",
      "  810 1137 1248 1498 1010  811 2392  630  483 1555 1194 1490  894 1414\n",
      " 1014  798 1566  866  889  626 1222 1872  908 1375 1444 1306 1625 1302\n",
      " 1314 1005 1604  963 1382 1482  926  764 1422  802 1052  778 1113 1095\n",
      " 1363 1632 1560 2121 1156 1175 1468 1575  625 1085  858  698 1079 1148\n",
      " 1644 1003  975 1041 1336 1210 1675 2000 1122 1035  861 1944  697  972\n",
      "  793 2036  832  716 1153 1088 1372 1472 1249 1136 1553 1163 1898  803\n",
      " 1719 1383 1445  596 1056 1629 1358  943 1619 1922 1536 1621 1215  993\n",
      "  841 1684  536 1478 1848 1869 1453  616 1192 1167 1142 1352  495  790\n",
      "  672 1394 1268 1287  953 1120  752 1319  847  904  914 1580 1856 1007\n",
      " 1026  939  784 1269  658 1742  788  735 1144  876 1112 1288 1310 1165\n",
      "  806 1620 1166 1071 1050 1276 1028  756 1344 1602 1470 1196  707  907\n",
      " 1208 1412  765  827  734  694 2402 1440 1128 1258  933 1689 1888  956\n",
      "  679  813 1533  888  786 1242  624 1663  833  979  575  849 1277 1634\n",
      " 1502 1161 1976 1652 1493 2069 1718 1131 1850 1792  916  999 1073 1484\n",
      " 1766  886 3228 1133  899 1801 1218 1368 2020 1378 1244 3138 1266 1476\n",
      "  605 2515 1509  751  334  820  880 1159 1601 1838 1680  767  664 1377\n",
      "  915  768  825 1069 1717 1126 1006 1048  897 1557 1389  996 1134 1496\n",
      "  846  576  877 1320  703 1429 2042 1521  989 2028  838 1473  779  770\n",
      "  924 1826 1402 1647 1058  927  600 1186 1940 1029 1032 1299 1054  807\n",
      " 1828 1548  980 1012 1116 1520 1350 1089 1554 1411  800 1567  981 1094\n",
      " 1051  822  755  909 2113  525  851 1486 1686 1181 2097 1454 1465 1679\n",
      " 1437  738 1839  792 2046  923 1291 1668 1195 1190  874  551 1419 2444\n",
      " 1238 1067 1391 1800 1264  372 1824  859 1576 1178 1325  971 1698 1776\n",
      " 1616 1146  948 1349 1464 1720 1038  742  757 1506 1836 1690 1220 1117\n",
      " 1973 1204 1614 1430 1110 1342  966  976 1062 1127 1285  773 1966 1428\n",
      " 1075 1309 1044  686 1661 1008  944 1489 2084 1434 1160  941 1516 1559\n",
      " 1099 1701 1307 1456  918 1779  702 1512 1039 1002 1646 1547 1036  676\n",
      " 1184 1462 1155 1090 1187  954  892 1709 1712  872 2217 1505 1068  951\n",
      " 2364 1670 1063 1636 1020 1105 1015 1001  546  480 1229 1272 1316 1617\n",
      " 1098 1788 1466  925 1905 1500 1207 1188 1381  965 1168  561  696 1542\n",
      "  824  783  673  869 1241 1118 1407  750  691 1574 1504  985 1657 1664\n",
      " 1082 2898 1687 1654 1055 1803 1532 2524 1733 1992 1771  930 1526 1091\n",
      " 1523 1364 1130 1096 1338 1103 1154  799  893  829 1240 1459 1251 1247\n",
      " 1390  438  950  887 1021 1552  812 1530  974  986 1042 1298 1811 1265\n",
      " 1640 1432  959 1831 1261 1170 2129  818 1124 2411  949 1624  831 1622\n",
      "  842  663  879  815 1630 1074 2196 1283 1660 1318 1211 2136 1138 1702\n",
      " 1507 1361 1024 1141 1173 2076 1140 1034 2110 1405  760 1987 1104  713\n",
      " 2018 1968 1332  935 1357  661 1724 1573 1582 1659 4692 1246  753 1203\n",
      " 1294 1902 1274 1787 1061  708 1584 1334  693 1284 1172 2156 2053  992\n",
      " 1078 1980 1281  814 2633 1571  984  754 2117  998 1416 1746 1525 1221\n",
      "  741 1569 1223  962 1537 1932 1423  913 1578 2073 1256]\n",
      "2ndFlrSF  =  [ 854    0  866  756 1053  566  983  752 1142 1218  668 1320  631  716\n",
      "  676  860 1519  530  808  977 1330  833  765  462  213  548  960  670\n",
      " 1116  876  612 1031  881  790  755  592  939  520  639  656 1414  884\n",
      "  729 1523  728  351  688  941 1032  848  836  475  739 1151  448  896\n",
      "  524 1194  956 1070 1096  467  547  551  880  703  901  720  316 1518\n",
      "  704 1178  754  601 1360  929  445  564  882  920  518  817 1257  741\n",
      "  672 1306  504 1304 1100  730  689  591  888 1020  828  700  842 1286\n",
      "  864  829 1092  709  844 1106  596  807  625  649  698  840  780  568\n",
      "  795  648  975  702 1242 1818 1121  371  804  325  809 1200  871 1274\n",
      " 1347 1332 1177 1080  695  167  915  576  605  862  495  403  838  517\n",
      " 1427  784  711  468 1081  886  793  665  858  874  526  590  406 1157\n",
      "  299  936  438 1098  766 1101 1028 1017 1254  378 1160  682  110  600\n",
      "  678  834  384  512  930  868  224 1103  560  811  878  574  910  620\n",
      "  687  546  902 1000  846 1067  914  660 1538 1015 1237  611  707  527\n",
      " 1288  832  806 1182 1040  439  717  511 1129 1370  636  533  745  584\n",
      "  812  684  595  988  800  677  573 1066  778  661 1440  872  788  843\n",
      "  713  567  651  762  482  738  586  679  644  900  887 1872 1281  472\n",
      " 1312  319  978 1093  473  664 1540 1276  441  348 1060  714  744 1203\n",
      "  783 1097  734  767 1589  742  686 1128 1111 1174  787 1072 1088 1063\n",
      "  545  966  623  432  581  540  769 1051  761  779  514  455 1426  785\n",
      "  521  252  813 1120 1037 1169 1001 1215  928 1140 1243  571 1196 1038\n",
      "  561  979  701  332  368  883 1336 1141  634  912  798  985  826  831\n",
      "  750  456  602  855  336  408  980  998 1168 1208  797  850  898 1054\n",
      "  895  954  772 1230  727  454  370  628  304  582 1122 1134  885  640\n",
      "  580 1112  653  220  240 1362  534  539  650  918  933  712 1796  971\n",
      " 1175  743  523 1216 2065  272  685  776  630  984  875  913  464 1039\n",
      " 1259  940  892  725  924  764  925 1479  192  589  992  903  430  748\n",
      "  587  994  950 1323  732 1357  557 1296  390 1185  873 1611  457  796\n",
      "  908  550  989  932  358 1392  349  691 1349  768  208  622  857  556\n",
      " 1044  708  626  904  510 1104  830  981  870  694 1152]\n",
      "LowQualFinSF  =  [  0 360 513 234 528 572 144 392 371 390 420 473 156 515  80  53 232 481\n",
      " 120 514 397 479 205 384]\n",
      "GrLivArea  =  [1710 1262 1786 1717 2198 1362 1694 2090 1774 1077 1040 2324  912 1494\n",
      " 1253  854 1004 1296 1114 1339 2376 1108 1795 1060 1600  900 1704  520\n",
      " 1317 1228 1234 1700 1561 2452 1097 1297 1057 1152 1324 1328  884  938\n",
      " 1150 1752 2149 1656 1452  955 1470 1176  816 1842 1360 1425 1739 1720\n",
      " 2945  780 1158 1111 1370 2034 2473 2207 1479  747 2287 2223  845 1718\n",
      " 1086 1605  988  952 1285 1768 1230 2142 1337 1563 1065 1474 2417 1560\n",
      " 1224 1526  990 1235  964 2291 1588  960  835 1225 1610 1732 1535 1226\n",
      " 1818 1992 1047  789 1517 1844 1855 1430 2696 2259 2320 1458 1092 1125\n",
      " 3222 1456 1123 1080 1199 1586  754  958  840 1348 1053 2157 2054 1327\n",
      " 1721 1682 1214 1959 1852 1764  864 1734 1385 1501 1728 1709  875 2035\n",
      " 1344  969 1993 1252 1200 1096 1968 1947 2462 1232 2668 1541  882 1616\n",
      " 1355 1867 2161 1707 1382 1767 1651 2158 2060 1920 2234  968 1525 1802\n",
      " 1340 2082 3608 1217 1593 2727 1431 1726 3112 2229 1713 1121 1279 1310\n",
      "  848 1284 1442 1696 1100 2062 1212 1392 1236 1436 1954 1248 1498 2267\n",
      " 1552 2392 1302 2520  987 1555 1194 2794  894 1960 1414 1744 1487 1566\n",
      "  866 1440 2110 1872 1928 1375 1668 2144 1306 1625 1640 1314 1604 1792\n",
      " 2574 1316  764 1422 1511 2192  778 1113 1939 1363 2270 1632 1548 2121\n",
      " 2022 1982 1468 1575 1250  858 1396 1919 1716 2263 1644 1003 1558 1950\n",
      " 1743 1336 3493 2000 2243 1406  861 1944  972 1118 2036 1641 1432 2353\n",
      " 2646 1472 2596 2468 2730 1163 2978  803 1719 1383 2134 1192 1056 1629\n",
      " 1358 1638 1922 1536 1621 1215 1908  841 1684 1112 1577 1478 1626 2728\n",
      " 1869 1453  720 1595 1167 1142 1352 1924 1505 1574 1394 1268 1287 1664\n",
      "  752 1319  904  914 2466 1856 1800 1691 1301 1797  784 1953 1269 1184\n",
      " 2332 1367 1961  788 1034 1144 1812 1550 1288  672 1572 1620 1639 1680\n",
      " 2172 2078 1276 1028 2097 1400 2624 1134 1602 2630 1196 1389  907 1208\n",
      " 1412 1198 1365  630 1661  694 2402 1573 1258 1689 1888 1886 1376 1183\n",
      "  813 1533 1756 1590 1242 1663 1666 1203 1935 1135 1660 1277 1634 1502\n",
      " 1969 1072 1976 1652  970 1493 2643 1131 1850 1826 1216  999 1073 1484\n",
      " 2414 1304 1578  886 3228 1820  899 1218 1801 1322 1911 1378 1041 1368\n",
      " 2020 2119 2344 1796 2080 1294 1244 4676 2398 1266  928 2713  605 2515\n",
      " 1509  827  334 1347 1724 1159 1601 1838 2285  767 1496 2183 1635  768\n",
      "  825 2094 1069 1126 2046 1048 1446 1557  996 1674 2295 1647 2504 2132\n",
      "  943 1692 1109 1477 1320 1429 2042 2775 2028  838  860 1473  935 1582\n",
      " 2296  924 1402 1556 1904 1915 1986 2008 3194 1029 2153 1032 1120 1054\n",
      "  832 1828 2262 2614  980 1512 1790 1116 1520 1350 1750 1554 1411 3395\n",
      "  800 1387  796 1567 1518 1929 2704 1766  981 1094 1839 1665 1510 1469\n",
      " 2113 1486 2448 1181 1936 2380 1679 1437 1180 1476 1369 1136 1441  792\n",
      "  923 1291 1761 1102 1419 4316 2519 1539 1137  616 1148 1391 1164 2576\n",
      " 1824  729 1178 2554 2418  971 1742 1698 1776 1146 2031  948 1349 1464\n",
      " 2715 2256 2640 1529 1140 2098 1026 1471 1386 2531 1547 2365 1506 1714\n",
      " 1836 3279 1220 1117 1973 1204 1614 1603 1110 1342 2084  901 2087 1145\n",
      " 1062 2013 1895 1564  773 3140 1688 2822 1128 1428 1576 2138 1309 1044\n",
      " 1008 1052  936 1733 1489 1434 2126 1223 1829 1516 1067 1559 1099 1482\n",
      " 1165 1416 1701 1775 2358 1646 1445 1779 1481 2654 1426 1039 1372 1002\n",
      " 1949  910 2610 2224 1155 1090 2230  892 1712 1393 2217 1683 1068  951\n",
      " 2240 2364 1670  902 1063 1636 2057 2274 1015 2002  480 1229 2127 2200\n",
      " 1617 1686 2374 1978 1788 2236 1466  925 1905 1500 2069 1971 1962 2403\n",
      " 1381  965 1958 2872 1894 1308 1098 1095  918 2019  869 1241 2612 2290\n",
      " 1940 2030 1851 1050  944  691 1504  985 1657 1522 1271 1022 1082 1132\n",
      " 2898 1264 3082 1654  954 1803 2329 2524 2868 1771  930 1977 1989 1523\n",
      " 1364 2184 1991 1338 2337 1103 1154 2260 1571 1611 2521  893 1240 1740\n",
      " 1459 1251 1247 1088  438  950 2622 2021 1690 1658 1964  833 1012  698\n",
      " 1005 1530 1981  974 2210  986 1020 1868 2828 1006 1298  932 1811 1265\n",
      " 1580 1876 1671 2108 3627 1261 3086 2345 1343 1124 2514 4476 1130 1221\n",
      " 1699 1624 1804 1622 1863 1630 1074 2196 1283 1845 1902 1211 1846 2136\n",
      " 1490 1138 1933 1702 1507 2620 1190 1188 1784 1948 1141 1173 2076 1553\n",
      " 2058 1405  874 2167 1987 1166 1675 1889 2018 3447 1524 1357 1395 2447\n",
      " 1659 1970 2372 5642 1246 1983 2526 1708 1122 1274 2810 2599 2112 1787\n",
      " 1923  708  774 2792 1334  693 1861  872 2169 1913 2156 2634 3238 1865\n",
      " 1078 1980 2601 1738 1475 1374 2633  790 2117 1762 2784 1746 1584 1912\n",
      " 2482 1687 1513 1608 2093 1840 1848 1569 2450 2201  804 1537 1932 1725\n",
      " 2555 2007  913 1346 2073 2340 1256]\n",
      "BsmtFullBath  =  [1 0 2 3]\n",
      "BsmtHalfBath  =  [0 1 2]\n",
      "FullBath  =  [2 1 3 0]\n",
      "HalfBath  =  [1 0 2]\n",
      "BedroomAbvGr  =  [3 4 1 2 0 5 6 8]\n",
      "KitchenAbvGr  =  [1 2 3 0]\n",
      "KitchenQual  =  ['Gd' 'TA' 'Ex' 'Fa']\n",
      "TotRmsAbvGrd  =  [ 8  6  7  9  5 11  4 10 12  3  2 14]\n",
      "Functional  =  ['Typ' 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev']\n",
      "Fireplaces  =  [0 1 2 3]\n",
      "FireplaceQu  =  ['NA' 'TA' 'Gd' 'Fa' 'Ex' 'Po']\n",
      "GarageType  =  ['Attchd' 'Detchd' 'BuiltIn' 'CarPort' 'NA' 'Basment' '2Types']\n",
      "GarageYrBlt  =  ['2003' '1976' '2001' '1998' '2000' '1993' '2004' '1973' '1931' '1939'\n",
      " '1965' '2005' '1962' '2006' '1960' '1991' '1970' '1967' '1958' '1930'\n",
      " '2002' '1968' '2007' '2008' '1957' '1920' '1966' '1959' '1995' '1954'\n",
      " '1953' 'NA' '1983' '1977' '1997' '1985' '1963' '1981' '1964' '1999'\n",
      " '1935' '1990' '1945' '1987' '1989' '1915' '1956' '1948' '1974' '2009'\n",
      " '1950' '1961' '1921' '1900' '1979' '1951' '1969' '1936' '1975' '1971'\n",
      " '1923' '1984' '1926' '1955' '1986' '1988' '1916' '1932' '1972' '1918'\n",
      " '1980' '1924' '1996' '1940' '1949' '1994' '1910' '1978' '1982' '1992'\n",
      " '1925' '1941' '2010' '1927' '1947' '1937' '1942' '1938' '1952' '1928'\n",
      " '1922' '1934' '1906' '1914' '1946' '1908' '1929' '1933']\n",
      "GarageFinish  =  ['RFn' 'Unf' 'Fin' 'NA']\n",
      "GarageCars  =  [2 3 1 0 4]\n",
      "GarageArea  =  [ 548  460  608  642  836  480  636  484  468  205  384  736  352  840\n",
      "  576  516  294  853  280  534  572  270  890  772  319  240  250  271\n",
      "  447  556  691  672  498  246    0  440  308  504  300  670  826  386\n",
      "  388  528  894  565  641  288  645  852  558  220  667  360  427  490\n",
      "  379  297  283  509  405  758  461  400  462  420  432  506  684  472\n",
      "  366  476  410  740  648  273  546  325  792  450  180  430  594  390\n",
      "  540  264  530  435  453  750  487  624  471  318  766  660  470  720\n",
      "  577  380  434  866  495  564  312  625  680  678  726  532  216  303\n",
      "  789  511  616  521  451 1166  252  497  682  666  786  795  856  473\n",
      "  398  500  349  454  644  299  210  431  438  675  968  721  336  810\n",
      "  494  457  818  463  604  389  538  520  309  429  673  884  868  492\n",
      "  413  924 1053  439  671  338  573  732  505  575  626  898  529  685\n",
      "  281  539  418  588  282  375  683  843  552  870  888  746  708  513\n",
      " 1025  656  872  292  441  189  880  676  301  474  706  617  445  200\n",
      "  592  566  514  296  244  610  834  639  501  846  560  596  600  373\n",
      "  947  350  396  864  304  784  696  569  628  550  493  578  198  422\n",
      "  228  526  525  908  499  508  694  874  164  402  515  286  603  900\n",
      "  583  889  858  502  392  403  527  765  367  426  615  871  570  406\n",
      "  590  612  650 1390  275  452  842  816  621  544  486  230  261  531\n",
      "  393  774  749  364  627  260  256  478  442  562  512  839  330  711\n",
      " 1134  416  779  702  567  832  326  551  606  739  408  475  704  983\n",
      "  768  632  541  320  800  831  554  878  752  614  481  496  423  841\n",
      "  895  412  865  630  605  602  618  444  397  455  409  820 1020  598\n",
      "  857  595  433  776 1220  458  613  456  436  812  686  611  425  343\n",
      "  479  619  902  574  523  414  738  354  483  327  756  690  284  833\n",
      "  601  533  522  788  555  689  796  808  510  255  424  305  368  824\n",
      "  328  160  437  665  290  912  905  542  716  586  467  582 1248 1043\n",
      "  254  712  719  862  928  782  466  714 1052  225  234  324  306  830\n",
      "  807  358  186  693  482  813  995  757 1356  459  701  322  315  668\n",
      "  404  543  954  850  477  276  518 1014  753 1418  213  844  860  748\n",
      "  248  287  825  647  342  770  663  377  804  936  722  208  662  754\n",
      "  622  620  370 1069  372  923  192]\n",
      "GarageQual  =  ['TA' 'Fa' 'Gd' 'NA' 'Ex' 'Po']\n",
      "GarageCond  =  ['TA' 'Fa' 'NA' 'Gd' 'Po' 'Ex']\n",
      "PavedDrive  =  ['Y' 'N' 'P']\n",
      "WoodDeckSF  =  [  0 298 192  40 255 235  90 147 140 160  48 240 171 100 406 222 288  49\n",
      " 203 113 392 145 196 168 112 106 857 115 120  12 576 301 144 300  74 127\n",
      " 232 158 352 182 180 166 224  80 367  53 188 105  24  98 276 200 409 239\n",
      " 400 476 178 574 237 210 441 116 280 104  87 132 238 149 355  60 139 108\n",
      " 351 209 216 248 143 365 370  58 197 263 123 138 333 250 292  95 262  81\n",
      " 289 124 172 110 208 468 256 302 190 340 233 184 201 142 122 155 670 135\n",
      " 495 536 306  64 364 353  66 159 146 296 125  44 215 264  88  89  96 414\n",
      " 519 206 141 260 324 156 220  38 261 126  85 466 270  78 169 320 268  72\n",
      " 349  42  35 326 382 161 179 103 253 148 335 176 390 328 312 185 269 195\n",
      "  57 236 517 304 198 426  28 316 322 307 257 219 416 344 380  68 114 327\n",
      " 165 187 181  92 228 245 503 315 241 303 133 403  36  52 265 207 150 290\n",
      " 486 278  70 418 234  26 342  97 272 121 243 511 154 164 173 384 202  56\n",
      " 321  86 194 421 305 117 550 509 153 394 371  63 252 136 186 170 474 214\n",
      " 199 728 436  55 431 448 361 362 162 229 439 379 356  84 635 325  33 212\n",
      " 314 242 294  30 128  45 177 227 218 309 404 500 668 402 283 183 175 586\n",
      " 295  32 366 736]\n",
      "OpenPorchSF  =  [ 61   0  42  35  84  30  57 204   4  21  33 213 112 102 154 159 110  90\n",
      "  56  32  50 258  54  65  38  47  64  52 138 104  82  43 146  75  72  70\n",
      "  49  11  36 151  29  94 101 199  99 234 162  63  68  46  45 122 184 120\n",
      "  20  24 130 205 108  80  66  48  25  96 111 106  40 114   8 136 132  62\n",
      " 228  60 238 260  27  74  16 198  26  83  34  55  22  98 172 119 208 105\n",
      " 140 168  28  39 148  12  51 150 117 250  10  81  44 144 175 195 128  76\n",
      "  17  59 214 121  53 231 134 192 123  78 187  85 133 176 113 137 125 523\n",
      " 100 285  88 406 155  73 182 502 274 158 142 243 235 312 124 267 265  87\n",
      " 288  23 152 341 116 160 174 247 291  18 170 156 166 129 418 240  77 364\n",
      " 188 207  67  69 131 191  41 118 252 189 282 135  95 224 169 319  58  93\n",
      " 244 185 200  92 180 263 304 229 103 211 287 292 241 547  91  86 262 210\n",
      " 141  15 126 236]\n",
      "EnclosedPorch  =  [  0 272 228 205 176  87 172 102  37 144  64 114 202 128 156  44  77 192\n",
      " 140 180 183  39 184  40 552  30 126  96  60 150 120 112 252  52 224 234\n",
      " 244 268 137  24 108 294 177 218 242  91 160 130 169 105  34 248 236  32\n",
      "  80 115 291 116 158 210  36 200  84 148 136 240  54 100 189 293 164 216\n",
      " 239  67  90  56 129  98 143  70 386 154 185 134 196 264 275 230 254  68\n",
      " 194 318  48  94 138 226 174  19 170 220 214 280 190 330 208 145 259  81\n",
      "  42 123 162 286 168  20 301 198 221 212  50  99]\n",
      "3SsnPorch  =  [  0 320 407 130 180 168 140 508 238 245 196 144 182 162  23 216  96 153\n",
      " 290 304]\n",
      "ScreenPorch  =  [  0 176 198 291 252  99 184 168 130 142 192 410 224 266 170 154 153 144\n",
      " 128 259 160 271 234 374 185 182  90 396 140 276 180 161 145 200 122  95\n",
      " 120  60 126 189 260 147 385 287 156 100 216 210 197 204 225 152 175 312\n",
      " 222 265 322 190 233  63  53 143 273 288 263  80 163 116 480 178 440 155\n",
      " 220 119 165  40]\n",
      "PoolArea  =  [  0 512 648 576 555 480 519 738]\n",
      "PoolQC  =  ['NA' 'Ex' 'Fa' 'Gd']\n",
      "Fence  =  ['NA' 'MnPrv' 'GdWo' 'GdPrv' 'MnWw']\n",
      "MiscFeature  =  ['NA' 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "MiscVal  =  [    0   700   350   500   400   480   450 15500  1200   800  2000   600\n",
      "  3500  1300    54   620   560  1400  8300  1150  2500]\n",
      "MoSold  =  [ 2  5  9 12 10  8 11  4  1  7  3  6]\n",
      "YrSold  =  [2008 2007 2006 2009 2010]\n",
      "SaleType  =  ['WD' 'New' 'COD' 'ConLD' 'ConLI' 'CWD' 'ConLw' 'Con' 'Oth']\n",
      "SaleCondition  =  ['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n",
      "SalePrice  =  [208500 181500 223500 140000 250000 143000 307000 200000 129900 118000\n",
      " 129500 345000 144000 279500 157000 132000 149000  90000 159000 139000\n",
      " 325300 139400 230000 154000 256300 134800 306000 207500  68500  40000\n",
      " 149350 179900 165500 277500 309000 145000 153000 109000  82000 160000\n",
      " 170000 130250 141000 319900 239686 249700 113000 127000 177000 114500\n",
      " 110000 385000 130000 180500 172500 196500 438780 124900 158000 101000\n",
      " 202500 219500 317000 180000 226000  80000 225000 244000 185000 144900\n",
      " 107400  91000 135750 136500 193500 153500 245000 126500 168500 260000\n",
      " 174000 164500  85000 123600 109900  98600 163500 133900 204750 214000\n",
      "  94750  83000 128950 205000 178000 118964 198900 169500 100000 115000\n",
      " 190000 136900 383970 217000 259500 176000 155000 320000 163990 136000\n",
      " 153900 181000  84500 128000  87000 150000 150750 220000 171000 231500\n",
      " 166000 204000 125000 105000 222500 122000 372402 235000  79000 109500\n",
      " 269500 254900 162500 412500 103200 152000 127500 325624 183500 228000\n",
      " 128500 215000 239000 163000 184000 243000 211000 501837 200100 120000\n",
      " 475000 173000 135000 153337 286000 315000 192000 148500 311872 104000\n",
      " 274900 171500 112000 143900 277000  98000 186000 252678 156000 161750\n",
      " 134450 210000 107000 311500 167240 204900  97000 386250 290000 106000\n",
      " 192500 148000 403000  94500 128200 216500  89500 185500 194500 318000\n",
      " 262500 110500 241500 137000  76500 276000 151000  73000 175500 179500\n",
      " 120500 266000 124500 201000 415298 228500 244600 179200 164700  88000\n",
      " 153575 233230 135900 131000 167000 142500 175000 158500 267000 149900\n",
      " 295000 305900  82500 360000 165600 119900 375000 188500 270000 187500\n",
      " 342643 354000 301000 126175 242000 324000 145250 214500  78000 119000\n",
      " 284000 207000 228950 377426 202900  87500 140200 151500 157500 437154\n",
      " 318061  95000 105900 177500 134000 280000 198500 147000 165000 162000\n",
      " 172400 134432 123000  61000 340000 394432 179000 187750 213500  76000\n",
      " 240000  81000 191000 426000 106500 129000  67000 241000 245500 164990\n",
      " 108000 258000 168000 339750  60000 222000 181134 149500 126000 142000\n",
      " 206300 275000 109008 195400  85400  79900 122500 212000 116000  90350\n",
      " 555000 162900 199900 119500 188000 256000 161000 263435  62383 188700\n",
      " 124000 178740 146500 187000 440000 251000 132500 208900 380000 297000\n",
      "  89471 326000 374000 164000  86000 133000 172785  91300  34900 430000\n",
      " 226700 289000 208300 164900 202665  96500 402861 265000 234000 106250\n",
      " 184750 315750 446261 200624 107500  39300 111250 272000 248000 213250\n",
      " 179665 229000 263000 112500 255500 121500 268000 325000 316600 135960\n",
      " 142600 224500 118500 146000 131500 181900 253293 369900  79500 185900\n",
      " 451950 138000 319000 114504 194201 217500 221000 359100 313000 261500\n",
      "  75500 137500 183200 105500 314813 305000 165150 139900 209500  93000\n",
      " 264561 274000 370878 143250  98300 205950 350000 145500  97500 197900\n",
      " 402000 423000 230500 173500 103600 257500 372500 159434 285000 227875\n",
      " 148800 392000 194700 755000 335000 108480 141500  89000 123500 138500\n",
      " 196000 312500 361919 213000  55000 302000 254000 179540  52000 102776\n",
      " 189000 130500 159500 341000 103000 236500 131400  93500 239900 299800\n",
      " 236000 265979 260400 275500 158900 179400 215200 337000 264132 216837\n",
      " 538000 134900 102000 395000 221500 175900 187100 161500 233000 107900\n",
      " 160200 146800 269790 143500 485000 582933 227680 135500 159950 144500\n",
      "  55993 157900 224900 271000 224000 183000 139500 232600 147400 237000\n",
      " 139950 174900 133500 189950 250580 248900 169000 200500  66500 303477\n",
      " 132250 328900 122900 154500 118858 142953 611657 125500 255000 154300\n",
      " 173733  75000  35311 238000 176500 145900 169990 193000 117500 184900\n",
      " 253000 239799 244400 150900 197500 172000 116500 214900 178900  37900\n",
      "  99500 182000 167500  85500 178400 336000 159895 255900 117000 395192\n",
      " 195000 197000 348000 173900 337500 121600 206000 232000 136905 119200\n",
      " 227000 203000 213490 194000 287000 293077 310000 119750  84000 315500\n",
      " 262280 278000 139600 556581  84900 176485 200141 185850 328000 167900\n",
      " 151400  91500 138800 155900  83500 252000  92900 176432 274725 134500\n",
      " 184100 133700 118400 212900 163900 259000 239500  94000 424870 174500\n",
      " 116900 201800 218000 235128 108959 233170 245350 625000 171900 154900\n",
      " 392500 745000 186700 104900 262000 219210 116050 271900 229456  80500\n",
      " 137900 367294 101800 138887 265900 248328 465000 186500 169900 171750\n",
      " 294000 165400 301500  99900 128900 183900 378500 381000 185750  68400\n",
      " 150500 281000 333168 206900 295493 111000 156500  72500  52500 155835\n",
      " 108500 283463 410000 156932 144152 216000 274300 466500  58500 237500\n",
      " 377500 246578 281213 137450 193879 282922 257000 223000 274970 182900\n",
      " 192140 143750  64500 394617 149700 149300 121000 179600  92000 287090\n",
      " 266500 142125 147500]\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns:\n",
    "    print(col ,\" = \",df_train[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Nominal and Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_var1 = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC']\n",
    "ordinal_var2 = ['ExterQual','ExterCond','BsmtQual','BsmtCond','HeatingQC','KitchenQual','FireplaceQu','GarageQual','GarageCond','PoolQC',\n",
    "               'Alley','Street','LotShape','Utilities','LandSlope','HouseStyle',\n",
    "               'BsmtExposure','BsmtFinType1','BsmtFinType2','Electrical','Functional','GarageFinish',\n",
    "                'PavedDrive','Fence']\n",
    "nominal_var = ['MSZoning','LandContour','LotConfig','Neighborhood','Condition1',\n",
    "'Condition2','BldgType','RoofStyle','RoofMatl',\n",
    "'Exterior1st','Exterior2nd' ,'MasVnrType','MasVnrArea',\n",
    "'Foundation','Heating' ,'CentralAir','GarageType' ,\n",
    "'MiscFeature','SaleCondition','SaleType'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ordinal_var1:\n",
    "    df_train[col].replace(to_replace=dict(NA = 0, Po=1,Fa = 2, TA =3,Gd =  4 ,Ex = 5), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Alley'].replace(to_replace=dict(Grvl = 0, Pave = 1, NA =  2), inplace=True)\n",
    "df_train['Street'].replace(to_replace=dict(Grvl = 0, Pave = 1), inplace=True)\n",
    "df_train['LotShape'].replace(to_replace=dict(IR3 = 0, IR2 = 1, IR1 =  2,Reg =  3), inplace=True)\n",
    "df_train['Utilities'].replace(to_replace=dict(ELO = 0, NoSeWa = 1, NoSeWr =  2,     AllPub =  3 ), inplace=True)\n",
    "df_train['LandSlope'].replace(to_replace=dict(Gtl = 0, Mod = 1, Sev =  2), inplace=True)\n",
    "df_train['BsmtExposure'].replace(to_replace=dict(NA = 0, No= 1, Mn =  2,    Av =  3 ,Gd = 4), inplace=True)\n",
    "df_train['BsmtFinType1'].replace(to_replace=dict(NA = 0, Unf = 1, LwQ =  2,    Rec =  3 , BLQ = 4 , ALQ = 5 , GLQ = 6), inplace=True)\n",
    "df_train['BsmtFinType2'].replace(to_replace=dict(NA = 0, Unf=1,LwQ = 2, Rec =3,BLQ =  4 ,ALQ = 5,GLQ = 6), inplace=True)\n",
    "df_train['Electrical'].replace(to_replace=dict(Mix = 0, FuseP = 1, FuseF =  2,     FuseA =  3 ,SBrkr = 4), inplace=True)\n",
    "df_train['Functional'].replace(to_replace=dict(Sal = 0, Sev = 1, Maj2 =  2,     Maj1 =  3 ,Mod = 4,Min2 =5, Min1 =6 , Typ=7), inplace=True)\n",
    "df_train['PavedDrive'].replace(to_replace=dict(N = 0, P = 1, Y =  2), inplace=True)\n",
    "df_train['Fence'].replace(to_replace=dict(NA = 0, MnWw = 1, GdWo =  2,     MnPrv =  3 ,GdPrv = 4), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['HouseStyle']=df_train['HouseStyle'].replace('1Story' , 0).replace( '1.5Fin' , 1).replace( '1.5Unf' ,  2).replace( '2Story' ,  3).replace( '2.5Fin' , 4).replace( '2.5Unf' , 5).replace(  'SFoyer', 6).replace('SLvl', 7 )\n",
    "df_train['GarageFinish']=df_train['GarageFinish'].replace('NA' , 0).replace('Unf' , 1).replace( 'RFn' , 2).replace(     'Fin' , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExterQual --->  [4 3 5 2]\n",
      "ExterCond --->  [3 4 2 1 5]\n",
      "BsmtQual --->  [4 3 5 0 2]\n",
      "BsmtCond --->  [3 4 0 2 1]\n",
      "HeatingQC --->  [5 4 3 2 1]\n",
      "KitchenQual --->  [4 3 5 2]\n",
      "FireplaceQu --->  [0 3 4 2 5 1]\n",
      "GarageQual --->  [3 2 4 0 5 1]\n",
      "GarageCond --->  [3 2 0 4 1 5]\n",
      "PoolQC --->  [0 5 2 4]\n",
      "Alley --->  [2 0 1]\n",
      "Street --->  [1 0]\n",
      "LotShape --->  [3 2 1 0]\n",
      "Utilities --->  [3 1]\n",
      "LandSlope --->  [0 1 2]\n",
      "HouseStyle --->  [3 0 1 2 6 7 5 4]\n",
      "BsmtExposure --->  [1 4 2 3 0]\n",
      "BsmtFinType1 --->  [6 5 1 3 4 0 2]\n",
      "BsmtFinType2 --->  [1 4 0 5 3 2 6]\n",
      "Electrical --->  [4 2 3 1 0 'NA']\n",
      "Functional --->  [7 6 3 5 4 2 1]\n",
      "GarageFinish --->  [2 1 3 0]\n",
      "PavedDrive --->  [2 0 1]\n",
      "Fence --->  [0 3 2 4 1]\n"
     ]
    }
   ],
   "source": [
    "for col in ordinal_var2:\n",
    "    print(col ,\"---> \",(df_train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_Values_present = ['MasVnrType','Alley','MasVnrArea','LotFrontage','Electrical','GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for col in NAN_Values_present:\n",
    "     df_train[col]=df_train[col].replace('NA',np.NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62</td>\n",
       "      <td>7917</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85</td>\n",
       "      <td>13175</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66</td>\n",
       "      <td>9042</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68</td>\n",
       "      <td>9717</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75</td>\n",
       "      <td>9937</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning LotFrontage  LotArea  Street  Alley  LotShape  \\\n",
       "1455  1456          60       RL          62     7917       1      2         3   \n",
       "1456  1457          20       RL          85    13175       1      2         3   \n",
       "1457  1458          70       RL          66     9042       1      2         3   \n",
       "1458  1459          20       RL          68     9717       1      2         3   \n",
       "1459  1460          20       RL          75     9937       1      2         3   \n",
       "\n",
       "     LandContour  Utilities  ... PoolArea  PoolQC Fence MiscFeature MiscVal  \\\n",
       "1455         Lvl          3  ...        0       0     0          NA       0   \n",
       "1456         Lvl          3  ...        0       0     3          NA       0   \n",
       "1457         Lvl          3  ...        0       0     4        Shed    2500   \n",
       "1458         Lvl          3  ...        0       0     0          NA       0   \n",
       "1459         Lvl          3  ...        0       0     0          NA       0   \n",
       "\n",
       "     MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "1455      8    2007        WD         Normal     175000  \n",
       "1456      2    2010        WD         Normal     210000  \n",
       "1457      5    2010        WD         Normal     266500  \n",
       "1458      4    2010        WD         Normal     142125  \n",
       "1459      6    2008        WD         Normal     147500  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning --->  ['RL' 'RM' 'C (all)' 'FV' 'RH']\n",
      "LandContour --->  ['Lvl' 'Bnk' 'Low' 'HLS']\n",
      "LotConfig --->  ['Inside' 'FR2' 'Corner' 'CulDSac' 'FR3']\n",
      "Neighborhood --->  ['CollgCr' 'Veenker' 'Crawfor' 'NoRidge' 'Mitchel' 'Somerst' 'NWAmes'\n",
      " 'OldTown' 'BrkSide' 'Sawyer' 'NridgHt' 'NAmes' 'SawyerW' 'IDOTRR'\n",
      " 'MeadowV' 'Edwards' 'Timber' 'Gilbert' 'StoneBr' 'ClearCr' 'NPkVill'\n",
      " 'Blmngtn' 'BrDale' 'SWISU' 'Blueste']\n",
      "Condition1 --->  ['Norm' 'Feedr' 'PosN' 'Artery' 'RRAe' 'RRNn' 'RRAn' 'PosA' 'RRNe']\n",
      "Condition2 --->  ['Norm' 'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe']\n",
      "BldgType --->  ['1Fam' '2fmCon' 'Duplex' 'TwnhsE' 'Twnhs']\n",
      "RoofStyle --->  ['Gable' 'Hip' 'Gambrel' 'Mansard' 'Flat' 'Shed']\n",
      "RoofMatl --->  ['CompShg' 'WdShngl' 'Metal' 'WdShake' 'Membran' 'Tar&Grv' 'Roll'\n",
      " 'ClyTile']\n",
      "Exterior1st --->  ['VinylSd' 'MetalSd' 'Wd Sdng' 'HdBoard' 'BrkFace' 'WdShing' 'CemntBd'\n",
      " 'Plywood' 'AsbShng' 'Stucco' 'BrkComm' 'AsphShn' 'Stone' 'ImStucc'\n",
      " 'CBlock']\n",
      "Exterior2nd --->  ['VinylSd' 'MetalSd' 'Wd Shng' 'HdBoard' 'Plywood' 'Wd Sdng' 'CmentBd'\n",
      " 'BrkFace' 'Stucco' 'AsbShng' 'Brk Cmn' 'ImStucc' 'AsphShn' 'Stone'\n",
      " 'Other' 'CBlock']\n",
      "MasVnrType --->  ['BrkFace' 'None' 'Stone' 'BrkCmn' nan]\n",
      "MasVnrArea --->  ['196' '0' '162' '350' '186' '240' '286' '306' '212' '180' '380' '281'\n",
      " '640' '200' '246' '132' '650' '101' '412' '272' '456' '1031' '178' '573'\n",
      " '344' '287' '167' '1115' '40' '104' '576' '443' '468' '66' '22' '284'\n",
      " '76' '203' '68' '183' '48' '28' '336' '600' '768' '480' '220' '184'\n",
      " '1129' '116' '135' '266' '85' '309' '136' '288' '70' '320' '50' '120'\n",
      " '436' '252' '84' '664' '226' '300' '653' '112' '491' '268' '748' '98'\n",
      " '275' '138' '205' '262' '128' '260' '153' '64' '312' '16' '922' '142'\n",
      " '290' '127' '506' '297' nan '604' '254' '36' '102' '472' '481' '108'\n",
      " '302' '172' '399' '270' '46' '210' '174' '348' '315' '299' '340' '166'\n",
      " '72' '31' '34' '238' '1600' '365' '56' '150' '278' '256' '225' '370'\n",
      " '388' '175' '296' '146' '113' '176' '616' '30' '106' '870' '362' '530'\n",
      " '500' '510' '247' '305' '255' '125' '100' '432' '126' '473' '74' '145'\n",
      " '232' '376' '42' '161' '110' '18' '224' '248' '80' '304' '215' '772'\n",
      " '435' '378' '562' '168' '89' '285' '360' '94' '333' '921' '762' '594'\n",
      " '219' '188' '479' '584' '182' '250' '292' '245' '207' '82' '97' '335'\n",
      " '208' '420' '170' '459' '280' '99' '192' '204' '233' '156' '452' '513'\n",
      " '261' '164' '259' '209' '263' '216' '351' '660' '381' '54' '528' '258'\n",
      " '464' '57' '147' '1170' '293' '630' '466' '109' '41' '160' '289' '651'\n",
      " '169' '95' '442' '202' '338' '894' '328' '673' '603' '1' '375' '90' '38'\n",
      " '157' '11' '140' '130' '148' '860' '424' '1047' '243' '816' '387' '223'\n",
      " '158' '137' '115' '189' '274' '117' '60' '122' '92' '415' '760' '27' '75'\n",
      " '361' '105' '342' '298' '541' '236' '144' '423' '44' '151' '975' '450'\n",
      " '230' '571' '24' '53' '206' '14' '324' '295' '396' '67' '154' '425' '45'\n",
      " '1378' '337' '149' '143' '51' '171' '234' '63' '766' '32' '81' '163'\n",
      " '554' '218' '632' '114' '567' '359' '451' '621' '788' '86' '796' '391'\n",
      " '228' '88' '165' '428' '410' '564' '368' '318' '579' '65' '705' '408'\n",
      " '244' '123' '366' '731' '448' '294' '310' '237' '426' '96' '438' '194'\n",
      " '119']\n",
      "Foundation --->  ['PConc' 'CBlock' 'BrkTil' 'Wood' 'Slab' 'Stone']\n",
      "Heating --->  ['GasA' 'GasW' 'Grav' 'Wall' 'OthW' 'Floor']\n",
      "CentralAir --->  ['Y' 'N']\n",
      "GarageType --->  ['Attchd' 'Detchd' 'BuiltIn' 'CarPort' 'NA' 'Basment' '2Types']\n",
      "MiscFeature --->  ['NA' 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "SaleCondition --->  ['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n",
      "SaleType --->  ['WD' 'New' 'COD' 'ConLD' 'ConLI' 'CWD' 'ConLw' 'Con' 'Oth']\n"
     ]
    }
   ],
   "source": [
    "for col in nominal_var:\n",
    "    print(col ,\"---> \",(df_train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train,columns=nominal_var)#,drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Fill missing Value(NaN) with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['LotFrontage', 'Electrical', 'GarageYrBlt'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns[df_train.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns[df_train.isnull().any()]:\n",
    "    df_train[col].fillna(df_train[col].mode()[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['LotFrontage'] = df_train['LotFrontage'].astype(int)\n",
    "df_train['GarageYrBlt'] = df_train['GarageYrBlt'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                int64\n",
       "MSSubClass        int64\n",
       "LotFrontage       int32\n",
       "LotArea           int64\n",
       "Street            int64\n",
       "                  ...  \n",
       "SaleType_ConLI    uint8\n",
       "SaleType_ConLw    uint8\n",
       "SaleType_New      uint8\n",
       "SaleType_Oth      uint8\n",
       "SaleType_WD       uint8\n",
       "Length: 539, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 539)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>SaleType_COD</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>68.267123</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>0.995890</td>\n",
       "      <td>1.903425</td>\n",
       "      <td>2.591781</td>\n",
       "      <td>2.998630</td>\n",
       "      <td>0.062329</td>\n",
       "      <td>1.562329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085616</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.083562</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.867808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>22.356355</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.394776</td>\n",
       "      <td>0.582296</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.276232</td>\n",
       "      <td>1.954122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279893</td>\n",
       "      <td>0.169128</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.036999</td>\n",
       "      <td>0.078298</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.058440</td>\n",
       "      <td>0.276824</td>\n",
       "      <td>0.045299</td>\n",
       "      <td>0.338815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea       Street  \\\n",
       "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    68.267123   10516.828082     0.995890   \n",
       "std     421.610009    42.300571    22.356355    9981.264932     0.063996   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     0.000000   \n",
       "25%     365.750000    20.000000    60.000000    7553.500000     1.000000   \n",
       "50%     730.500000    50.000000    63.000000    9478.500000     1.000000   \n",
       "75%    1095.250000    70.000000    79.000000   11601.500000     1.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000     1.000000   \n",
       "\n",
       "             Alley     LotShape    Utilities    LandSlope   HouseStyle  ...  \\\n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000  ...   \n",
       "mean      1.903425     2.591781     2.998630     0.062329     1.562329  ...   \n",
       "std       0.394776     0.582296     0.052342     0.276232     1.954122  ...   \n",
       "min       0.000000     0.000000     1.000000     0.000000     0.000000  ...   \n",
       "25%       2.000000     2.000000     3.000000     0.000000     0.000000  ...   \n",
       "50%       2.000000     3.000000     3.000000     0.000000     1.000000  ...   \n",
       "75%       2.000000     3.000000     3.000000     0.000000     3.000000  ...   \n",
       "max       2.000000     3.000000     3.000000     2.000000     7.000000  ...   \n",
       "\n",
       "       SaleCondition_Partial  SaleType_COD  SaleType_CWD  SaleType_Con  \\\n",
       "count            1460.000000   1460.000000   1460.000000   1460.000000   \n",
       "mean                0.085616      0.029452      0.002740      0.001370   \n",
       "std                 0.279893      0.169128      0.052289      0.036999   \n",
       "min                 0.000000      0.000000      0.000000      0.000000   \n",
       "25%                 0.000000      0.000000      0.000000      0.000000   \n",
       "50%                 0.000000      0.000000      0.000000      0.000000   \n",
       "75%                 0.000000      0.000000      0.000000      0.000000   \n",
       "max                 1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  SaleType_New  \\\n",
       "count     1460.000000     1460.000000     1460.000000   1460.000000   \n",
       "mean         0.006164        0.003425        0.003425      0.083562   \n",
       "std          0.078298        0.058440        0.058440      0.276824   \n",
       "min          0.000000        0.000000        0.000000      0.000000   \n",
       "25%          0.000000        0.000000        0.000000      0.000000   \n",
       "50%          0.000000        0.000000        0.000000      0.000000   \n",
       "75%          0.000000        0.000000        0.000000      0.000000   \n",
       "max          1.000000        1.000000        1.000000      1.000000   \n",
       "\n",
       "       SaleType_Oth  SaleType_WD  \n",
       "count   1460.000000  1460.000000  \n",
       "mean       0.002055     0.867808  \n",
       "std        0.045299     0.338815  \n",
       "min        0.000000     0.000000  \n",
       "25%        0.000000     1.000000  \n",
       "50%        0.000000     1.000000  \n",
       "75%        0.000000     1.000000  \n",
       "max        1.000000     1.000000  \n",
       "\n",
       "[8 rows x 539 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OverallQual', 'ExterQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea',\n",
       "       'KitchenQual', 'GarageCars', 'GarageArea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[abs(df_train.corr()['SalePrice']) > 0.6][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'MSSubClass', 'LotArea', 'Street', 'Alley', 'LotShape',\n",
       "       'Utilities', 'LandSlope', 'HouseStyle', 'OverallCond',\n",
       "       ...\n",
       "       'SaleCondition_Alloca', 'SaleCondition_Family', 'SaleCondition_Normal',\n",
       "       'SaleType_COD', 'SaleType_CWD', 'SaleType_Con', 'SaleType_ConLD',\n",
       "       'SaleType_ConLI', 'SaleType_ConLw', 'SaleType_Oth'],\n",
       "      dtype='object', length=499)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns[abs(df_train.corr()['SalePrice']) < 0.3][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.loc[:,~df_train.columns.isin(['SalePrice'])]\n",
    "Y = df_train.loc[:,'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 121)\n",
      "(1095, 75)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Make an instance of the Model\n",
    "# Principle COmponent Analysis\n",
    "pca = PCA(0.95)\n",
    "print(X_train.shape)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05544889,  0.        , -0.        ,  0.03537424,  0.        ,\n",
       "        0.        , -0.01031345, -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        , -0.        , -0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LASSO (L1)\n",
    "#\"Least Absolute Shrinkage and Selection Operator\"\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=.01)\n",
    "lasso.fit(X_train, Y_train)\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0., -0.,  0.,  0.,  0., -0., -0., -0.,  0.,  0.,  0., -0.,\n",
       "        0.,  0., -0., -0.,  0.,  0., -0.,  0., -0., -0., -0.,  0., -0.,\n",
       "       -0., -0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0., -0.,  0., -0.,\n",
       "        0., -0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0.,\n",
       "       -0., -0., -0.,  0., -0.,  0., -0., -0., -0.,  0., -0., -0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=.1)\n",
    "lasso.fit(X_train, Y_train)\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002125468047533673"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "Y_pred = reg.predict(X_test)\n",
    "Y_pred\n",
    "mean_squared_error(Y_test.values,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pd.DataFrame([Y_pred,Y_test])\n",
    "res = res.T\n",
    "res.columns = ['Y_pred','Y_test']\n",
    "\n",
    "res.head()\n",
    "\n",
    "res[['Y_pred', 'Y_test']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestRegressor(random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { #10,50,100,500,1000\n",
    "    'n_estimators': [10,75,200],\n",
    "    'max_depth' : [6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid,\\\n",
    "                      cv= 2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'gini'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1246, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 336, in fit\n",
      "    criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "KeyError: 'entropy'\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gini'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-c9fa9160cd34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mCV_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1246\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1247\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    334\u001b[0m                                                          self.n_classes_)\n\u001b[0;32m    335\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                 criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n\u001b[0m\u001b[0;32m    337\u001b[0m                                                          n_samples)\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gini'"
     ]
    }
   ],
   "source": [
    "CV_rfc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_rfc.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "abr = AdaBoostRegressor(random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[40,50,60],\n",
    "              'learning_rate':[0.35,0.4,0.6]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_abr = GridSearchCV(estimator=abr, param_grid=param_grid,\n",
    "                      cv= 2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=AdaBoostRegressor(random_state=7),\n",
       "             param_grid={'learning_rate': [0.35, 0.4, 0.6],\n",
       "                         'n_estimators': [40, 50, 60]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_abr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.6, 'n_estimators': 60}\n"
     ]
    }
   ],
   "source": [
    "print(CV_abr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59556843 0.60125747 0.59887859 0.58026333 0.59638377 0.60323198\n",
      " 0.60219045 0.60350595 0.60515985]\n"
     ]
    }
   ],
   "source": [
    "print(CV_abr.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = xgb.XGBRegressor(colsample_bytree=0.2, gamma=0.0, learning_rate=0.01, max_depth=4,\n",
    "                        min_child_weight=1.5, n_estimators=7200, reg_alpha=0.9, reg_lambda=0.6, \n",
    "                        subsample=0.2).fit(X_train, Y_train)\n",
    "\n",
    "en = ElasticNet(alpha =0.0005, l1_ratio=0.9, max_iter=10000).fit(X_train, Y_train)\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', \n",
    "                                min_samples_leaf=15, min_samples_split=10, loss='huber').fit(X_train, Y_train)\n",
    "\n",
    "la = Lasso(alpha=0.0005, max_iter=10000).fit(X_train, Y_train)\n",
    "\n",
    "sv = SVR(C= 20, epsilon= 0.008, gamma=0.0003).fit(X_train, Y_train)\n",
    "\n",
    "rid = Ridge(alpha=20).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_score = np.sqrt(-cross_val_score(xgb.XGBRegressor(colsample_bytree=0.2, gamma=0.0, learning_rate=0.01, max_depth=4,\n",
    "                        min_child_weight=1.5, n_estimators=7200, reg_alpha=0.9, reg_lambda=0.6, \n",
    "                        subsample=0.2), X_train, Y_train, scoring='neg_mean_squared_error')).mean()\n",
    "\n",
    "en_score = np.sqrt(-cross_val_score(ElasticNet(alpha =0.0005, l1_ratio=0.9, max_iter=10000), X_train, Y_train,\n",
    "                                    scoring='neg_mean_squared_error')).mean()\n",
    "\n",
    "gbr_score = np.sqrt(-cross_val_score(GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4,\n",
    "                                                              max_features='sqrt', min_samples_leaf=15,\n",
    "                                                              min_samples_split=10, loss='huber'), X_train, Y_train,\n",
    "                                     scoring='neg_mean_squared_error')).mean()\n",
    "\n",
    "la_score = np.sqrt(-cross_val_score(Lasso(alpha=0.0005, max_iter=10000), X_train, Y_train,\n",
    "                                    scoring='neg_mean_squared_error')).mean()\n",
    "\n",
    "sv_score = np.sqrt(-cross_val_score(SVR(C= 20, epsilon= 0.008, gamma=0.0003), X_train, Y_train,\n",
    "                                    scoring='neg_mean_squared_error')).mean()\n",
    "\n",
    "rid_score = np.sqrt(-cross_val_score(Ridge(alpha=20), X_train, Y_train,scoring='neg_mean_squared_error')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Names</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>0.053424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.047595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingRegression</td>\n",
       "      <td>0.051942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.047860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.047088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.047514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Names      RMSE\n",
       "0                XGBRegressor  0.053424\n",
       "1                  ElasticNet  0.047595\n",
       "2  GradientBoostingRegression  0.051942\n",
       "3                       Lasso  0.047860\n",
       "4                         SVR  0.047088\n",
       "5                       Ridge  0.047514"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=['XGBRegressor', 'ElasticNet', 'GradientBoostingRegression', 'Lasso', 'SVR', 'Ridge']\n",
    "Scores = [regr_score, en_score, gbr_score, la_score, sv_score, rid_score]\n",
    "\n",
    "Models = pd.DataFrame(dict(Names=names, RMSE=Scores))\n",
    "\n",
    "Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
